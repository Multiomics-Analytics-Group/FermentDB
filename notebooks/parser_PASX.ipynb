{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea153251",
   "metadata": {},
   "source": [
    "# Parser for PAS-X Data File\n",
    "This notebook focuses on parsing data from PAS-X software to extract and model/organize high-cell density fermentation data.  \n",
    "\n",
    "PAS-X file contains data about one project which contains several runs, and each run contains data of several features.   \n",
    "\n",
    "The <b>primary objective</b> is to parse the PAS-X data file with configs files in order to generate document structures (JSON) for our graph, concretely node documents and edge documents such as: project, run, strain, species, etc.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b492d2",
   "metadata": {},
   "source": [
    "### 0. Install dependencies, import modules and define file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3b96a6a9-cc90-46f7-9a29-ed9e73623d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas\n",
    "#!pip install pyarango"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33ae25ad-ad5c-4bff-957c-1d9a124d7864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import json\n",
    "import hashlib\n",
    "from functools import reduce\n",
    "import operator\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30c3e111-55d5-4282-a0eb-515d579d85d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input paths\n",
    "data_dir = '../data'\n",
    "data_path = os.path.join(data_dir, \"20240328_dataset for ambrDB_DDBproject.json\")\n",
    "strain_mapping_path = os.path.join(data_dir, \"strain_metadata_benchling.csv\")\n",
    "taxa_mapping_path = os.path.join(data_dir, \"organism_metadata_benchling.csv\")\n",
    "project_metadata_mapping_path = os.path.join(data_dir, \"FermentDB_metadata_project_metadata.csv\")\n",
    "medium_mapping_path = os.path.join(data_dir, \"medium_metadata_benchling.csv\")\n",
    "ingredient_mapping_path = os.path.join(data_dir, \"FermentDB_metadata_medium_concentrations.csv\")\n",
    "experiment_mapping_path = os.path.join(data_dir, \"experiment_metadata_benchling.csv\")\n",
    "var_description_mapping_path = os.path.join(\"../notebooks/bioprocess_ontology/bioprocess_variables_description.json\")\n",
    "imodulon_files = {'e_coli': {'precise1k': os.path.join(data_dir, 'iM_table.csv')}}\n",
    "\n",
    "config_dir = '../config'\n",
    "main_config_path = os.path.join(config_dir, 'main_parser_config.yaml')\n",
    "var_config_path = os.path.join(config_dir, 'var_parser_config.yaml')\n",
    "\n",
    "\n",
    "# Output paths\n",
    "output_dir = '../output'\n",
    "nodes_path = os.path.join(output_dir, \"fermentdb_nodes_full.json\")\n",
    "edges_path = os.path.join(output_dir, \"fermentdb_edges_full.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a5b857",
   "metadata": {},
   "source": [
    "### 1. Load data and config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e34617eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['end', 'created_by', 'editable', 'unit_operations', 'workflow', 'creation_time', 'project', 'description', 'status', 'name', 'event_names', 'key_variable', 'id', 'type', 'result_notes', 'progress', 'country', 'manager', 'trending_settings', 'deletable', 'modification_time', 'batch_phase_names', 'tags', 'start', 'departments', 'editable_plots', 'sites', 'batches'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load PASX data file\n",
    "with open(data_path, 'r') as dbfile:\n",
    "    data = json.load(dbfile)\n",
    "\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42640478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Project': {'_key': 'project', 'id': 'project'},\n",
       " 'Country': {'_key': 'country', 'id': 'country', 'name': 'country'},\n",
       " 'User': {'_key': 'manager/username',\n",
       "  'id': 'manager/username',\n",
       "  'name': 'manager/first_name',\n",
       "  'surname': 'manager/last_name'},\n",
       " 'Experiment': {'batches': {'variables': {'name': 'Experiment'}}},\n",
       " 'Run': {'batches': {'_key': 'id',\n",
       "   'id': 'id',\n",
       "   'name': 'name',\n",
       "   'run_start': 'batch_start',\n",
       "   'run_end': 'batch_end',\n",
       "   'run_date': 'creation_time',\n",
       "   'variables': {'is_control': 'Control?', 'replicate_number': 'Replicate #'},\n",
       "   'phases': 'phases',\n",
       "   'events': 'events'}},\n",
       " 'Fermenter': {'batches': {'variables': {'name': 'Container Type'}}},\n",
       " 'Medium': {'batches': {'variables': {'name': 'Base Medium'}}},\n",
       " 'Phase': {'id': 'batch_phase_names',\n",
       "  'name': 'batch_phase_names',\n",
       "  'batches': {'phases': {'name': 'name'}}},\n",
       " 'Event': {'id': 'event_names', 'name': 'event_names'},\n",
       " 'Calculated_var': {'batches': {'variables': 'variables'}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load main_parser_config.yaml\n",
    "with open(main_config_path, 'r') as cfile:\n",
    "    main_config = yaml.load(cfile, Loader=yaml.SafeLoader)\n",
    "\n",
    "main_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d0c465e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cultivation_cond': {'temperature_setpoint_celsius': 'Temperature Setpoint (C)',\n",
       "  'pH_setpoint': 'pH Setpoint',\n",
       "  'ph_control_base_solution': 'pH Control Base Solution',\n",
       "  'ph_control_acid_solution': 'pH Control Acid Solution',\n",
       "  'culture_id': 'Main Culture ID',\n",
       "  'seed': 'Seed',\n",
       "  'DO_control_setpoint_percentage': 'DO Control Setpoint (%)',\n",
       "  'DO_control_cascade_level1': 'DO Control Cascade Level 1',\n",
       "  'maximum_stirring_speed_rpm': 'Maximum Stirring or Shaking Speed (rpm)',\n",
       "  'minimum_stirring_speed_rpm': 'Minimum Stirring or Shaking Speed (rpm)',\n",
       "  'DO_control_cascade_level2': 'DO Control Cascade Level 2',\n",
       "  'aeration_gas_type': 'Aeration Gas Type',\n",
       "  'maximum_aeration_slpm': 'Maximum Aeration (slpm)',\n",
       "  'minimum_aeration_slpm': 'Minimum Aeration (slpm)',\n",
       "  'DO_control_cascade_level3': 'DO Control Cascade Level 3',\n",
       "  'starting_OD': 'Starting OD',\n",
       "  'final_seed_od': 'Final Seed OD',\n",
       "  'initial_culture_volume': 'Initial Culture VolumeNone',\n",
       "  'culture_volume_unit': 'Culture Volume Unit'},\n",
       " 'Process_var': {'do': 'DO',\n",
       "  'ph': 'pH',\n",
       "  'temperature': 'Temperature',\n",
       "  'pressure': 'Pressure',\n",
       "  'liquid_volume': 'Liquid volume',\n",
       "  'liquid_volume_without_corrected_samples': 'Liquid volume (without corrected samples)',\n",
       "  'sample_mass': 'Sample mass',\n",
       "  'sample_volume': 'Sample volume',\n",
       "  'accumulated_sample_volume': 'Accumulated sample volume',\n",
       "  'acid_volume': 'Acid volume',\n",
       "  'base_volume': 'Base volume',\n",
       "  'base_rate': 'Base rate',\n",
       "  'feed_amount': 'Feed amount',\n",
       "  'feed_volume': 'Feed 1 volume',\n",
       "  'feed_rate_volumetric': 'Feed 1 rate volumetric',\n",
       "  'stirrer_speed': 'Stirrer speed',\n",
       "  'air_flow': 'Air flow',\n",
       "  'o2_flow': 'Oxygen flow',\n",
       "  'o2_percentage_inflow': 'Inlet air O2',\n",
       "  'co2_percentage_inflow': 'Inlet air CO2',\n",
       "  'OD': 'OD',\n",
       "  'OUR': 'O2 uptake rate',\n",
       "  'CER': 'CO2 evolution rate'},\n",
       " 'Compound': {'d_glucose': 'D-glucose',\n",
       "  'melatonin': 'melatonin',\n",
       "  'tryptophan': 'tryptophan',\n",
       "  'acetic_acid': 'acetic acid',\n",
       "  'caffeine': 'caffeine',\n",
       "  'citric_acid': 'citric acid',\n",
       "  'lactate': 'lactate',\n",
       "  'pyruvic_acid': 'pyruvic acid',\n",
       "  'succinic_acid': 'succinic acid'},\n",
       " 'Calculated_var': {'OTR': 'OTR',\n",
       "  'CTR': 'CTR',\n",
       "  'RQ': 'RQ',\n",
       "  'formed_co2': 'Formed CO2',\n",
       "  'consumed_o2': 'Consumed O2',\n",
       "  'offgas_co2': 'Offgas CO2',\n",
       "  'offgas_o2': 'Offgas O2',\n",
       "  'biomass_concentration': 'Biomass concentration',\n",
       "  'volume_addednone': 'Volume AddedNone',\n",
       "  'liquid_volume_downscaled': 'Liquid volume downscaled',\n",
       "  'volume_unitnone': 'Volume UnitNone',\n",
       "  'volume_to_addnone': 'Volume to AddNone',\n",
       "  'dilution_rate': 'D',\n",
       "  'c_balance': 'C balance',\n",
       "  'c_balance_c_mols': 'C balance (using c-mols)',\n",
       "  'c_balance_to_substrate': 'Elemental C balance with reference to substrate',\n",
       "  'dor_balance': 'DoR balance',\n",
       "  'dor_yields': 'DoR (from yields)',\n",
       "  'substrate_consumed': 'D-glucose consumed',\n",
       "  'substrate_consumed_molar': 'D-glucose consumed molar',\n",
       "  'substrate_consumed_c-molar': 'D-glucose consumed c-molar',\n",
       "  'substrate_lost_in_sample': 'D-glucose lost in sample',\n",
       "  'substrate_uptake_rate': 'D-glucose uptake rate',\n",
       "  'substrate_uptake_rate_molar': 'D-glucose uptake rate molar',\n",
       "  'substrate_specific_uptake_rate': 'D-glucose specific uptake rate',\n",
       "  'substrate_specific_uptake_rate_molar': 'D-glucose specific uptake rate molar',\n",
       "  'substrate_specific_uptake_rate_mean_in_feed': 'D-glucose specific uptake rate_mean in Feed',\n",
       "  'substrate_specific_uptake_rate_max_in_feed': 'D-glucose specific uptake rate_max in Feed',\n",
       "  'substrate_specific_uptake_rate_min_in_feed': 'D-glucose specific uptake rate_min in Feed',\n",
       "  'substrate_yield_X': 'D-glucose yield (X)',\n",
       "  'substrate_yield_X_molar': 'D-glucose yield molar (X)',\n",
       "  'substrate_yield_X_c_molar': 'D-glucose yield c-molar (X)',\n",
       "  'o2_decimal': 'O2 decimal',\n",
       "  'o2_partial_integration': 'O2 partial integration',\n",
       "  'o2_accumulated': 'O2 accumulated',\n",
       "  'o2_accumulated_downscaled': 'O2 accumulated downscaled',\n",
       "  'o2_q': 'O2 Q',\n",
       "  'o2_molar': 'O2 molar',\n",
       "  'o2_specific_uptake_rate': 'O2 specific uptake rate',\n",
       "  'o2_yield_S': 'O2 yield (S)',\n",
       "  'o2_yield_S_c_molar': 'O2 yield c-molar (S)',\n",
       "  'o2_yield_X': 'O2 yield (X)',\n",
       "  'compound_formed': 'Acetic acid formed',\n",
       "  'compound_formed_molar': 'Acetic acid formed molar',\n",
       "  'compound_formed_c_molar': 'Acetic acid formed c-molar',\n",
       "  'compound_lost_in_sample': 'Acetic acid lost in sample',\n",
       "  'residual_compound_amount': 'Residual Acetic acid amount Residual Citric acid amount Residual D-glucose amount Residual Ethanol amount Residual Lactate amount Residual Pyruvic acid amount Residual Succinic acid amount',\n",
       "  'compound_formation_rate': 'Acetic acid formation rate',\n",
       "  'compound_formation_rate_molar': 'Acetic acid formation rate molar',\n",
       "  'compound_specific_formation_rate': 'Acetic acid specific formation rate',\n",
       "  'compound_specific_formation_rate_molar': 'Acetic acid specific formation rate molar',\n",
       "  'compound_yield_S': 'Acetic acid yield (S)',\n",
       "  'compound_yield_S_molar': 'Acetic acid yield molar (S)',\n",
       "  'compound_yield_S_c_molar': 'Acetic acid yield c-molar (S)',\n",
       "  'compound_yield_X': 'Actic acid yield (X)',\n",
       "  'compound_yield_X_molar': 'Acetic acid yield molar (X)',\n",
       "  'compound_yield_X_c_molar': 'Acetic acid yield c-molar (X)',\n",
       "  'co2_decimal': 'CO2 decimal',\n",
       "  'co2_molar': 'CO2 molar',\n",
       "  'co2_partial_integration': 'CO2 partial integration',\n",
       "  'co2_accumulated': 'CO2 accumulated',\n",
       "  'co2_accumulated_downscaled': 'CO2 accumulated downscaled',\n",
       "  'co2_q': 'CO2 Q',\n",
       "  'co2_specific_evolution_rate': 'CO2 specific evolution rate',\n",
       "  'co2_yield_S': 'CO2 yield (S)',\n",
       "  'co2_yield_S_c_molar': 'CO2 yield c-molar (S)',\n",
       "  'co2_yield_X': 'CO2 yield (X)',\n",
       "  'biomass_amount': 'Biomass amount',\n",
       "  'biomass_amount_molar': 'Biomass amount molar',\n",
       "  'biomass_lost_in_sample': 'Biomas lost in sample',\n",
       "  'biomass_formed': 'Biomass formed',\n",
       "  'biomass_formed_molar': 'Biomass formed molar',\n",
       "  'biomass_formed_c_molar': 'Biomass formed c-molar',\n",
       "  'biomass_formation_rate': 'Biomass formation rate',\n",
       "  'biomass_formation_rate_molar': 'Biomass formation rate molar',\n",
       "  'biomass_specific_growth_rate_u': 'Biomass specific growth rate μ',\n",
       "  'biomass_specific_growth_rate_u_mean_in_feed': 'Biomass specific growth rate μ_mean in Feed',\n",
       "  'biomass_specific_growth_rate_u_max_in_feed': 'Biomass specific growth rate μ_max in Feed',\n",
       "  'biomass_specific_growth_rate_u_min_in_feed': 'Biomass specific growth rate μ_min in Feed',\n",
       "  'biomass_yield_S': 'Biomass yield (S)',\n",
       "  'biomass_yield_S_molar': 'Biomass yield molar (S)',\n",
       "  'biomass_yield_S_c_molar': 'Biomass yield c-molar (S)'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load var_parser_config.yaml\n",
    "with open(var_config_path, 'r') as cfile:\n",
    "    var_config = yaml.load(cfile, Loader=yaml.SafeLoader)\n",
    "\n",
    "var_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29be854",
   "metadata": {},
   "source": [
    "### 2. Create node collections dictionary structure\n",
    "Create a dictionary structure for nodes collections with parser_config file and PASX data file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03a4becc-79a7-4191-a505-decba440eb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function and Variable Definitions\n",
    "\n",
    "compound = [\"acetic acid\", \"citric acid\", \"d-glucose\", \"ethanol\", \"lactate\", \"pyruvic acid\", \"succnic acid\", \"tryptophan\", \"melatonin\"]\n",
    "substrate = [\"d-glucose\"]\n",
    "product = [\"tryptophan\", \"melatonin\", \"biomass\"] # biomass?\n",
    "\n",
    "def get_from_nested_dict(data_dict:dict, map_list:list):\n",
    "    '''\n",
    "    Extracts value from a nested dictionary given a list of keys (different levels).\n",
    "\n",
    "    parameters:\n",
    "        data_dict (dict): dictionary structure \n",
    "        map_list (list): list of nested keys\n",
    "\n",
    "    return:\n",
    "        nested_value: nested value given the provided list of keys\n",
    "\n",
    "    example:\n",
    "        >>> data_dict = {'a': {'b': {'c': 5}}}\n",
    "        >>> value = get_from_nested_dict(data_dict=data_dict, map_list=['a', 'b', 'c'])\n",
    "        >>> print(value)\n",
    "        5\n",
    "    '''\n",
    "\n",
    "    nested_value = None\n",
    "    try:\n",
    "        nested_value = reduce(operator.getitem, map_list, data_dict)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return nested_value\n",
    "\n",
    "def get_hash(key, prefix=\"\"):\n",
    "    '''\n",
    "    Get a hash value for a given key:\n",
    "    Hash a string using SHA-1, before encode key string into bytes using the UTF-8 encoding, as the sha1() expects bytes as input. \n",
    "    Convert the binary hash value into a hexadecimal string and then into an 8-digit integer.\n",
    "    Convert it to a string and add a prefix.\n",
    "\n",
    "    parameters:\n",
    "        key (str): Input string to be hashed.\n",
    "        prefix (str, optional): Prefix to prepend to the hash value. Defaults to \"\".\n",
    "\n",
    "    return:\n",
    "        str: Hash value.\n",
    "\n",
    "    example:\n",
    "        >>> input_key = \"example_key\"\n",
    "        >>> get_hash(input_key, prefix=\"HASH_\")\n",
    "        'HASH_45200d86'\n",
    "    '''\n",
    "    hkey = str(int(hashlib.sha1(key.encode(\"utf-8\")).hexdigest(),16) % (10 ** 8))\n",
    "    hkey = f\"{prefix}{hkey}\"\n",
    "    \n",
    "    return hkey\n",
    "\n",
    "def generate_node_collections(data:dict, config:dict) -> dict:\n",
    "    collections = {}\n",
    "    for key1 in config:\n",
    "        collections[key1]= {}\n",
    "        for key2 in config[key1]:\n",
    "            if type(config[key1][key2]) != dict:\n",
    "                key_list = config[key1][key2].split('/') \n",
    "                value = get_from_nested_dict(data, key_list)\n",
    "                if key2 == '_key':\n",
    "                    value = str(value) # keys must be str in ArangoDB\n",
    "                    if key1 == 'Project':\n",
    "                        value = get_hash(value, prefix=\"P\")\n",
    "                    elif key1 == 'Country':\n",
    "                        value = get_hash(value, prefix=\"C\")\n",
    "                    elif key1 == 'User':\n",
    "                        value = get_hash(value, prefix=\"U\")\n",
    "                    elif key1 == 'Event':\n",
    "\n",
    "    return collections\n",
    "\n",
    "def get_collections_from_pasx(data: dict, config: dict) -> dict:\n",
    "    '''\n",
    "    This function creates a dictionary with the node collections expected\n",
    "    in FermentDB. It requires a dictionary with the data exported from PASX\n",
    "    in json format, and a configuration file that specifies the mapping between\n",
    "    PASX and FermentDB structure. See example in '/config/main_parser_config.yaml'\n",
    "\n",
    "    parameters:\n",
    "        data (dict): dictionary with the data read from PASX in json format\n",
    "        config (dict): mapping configuration to adapt to FermentDB structure\n",
    "\n",
    "    return:\n",
    "        collections (dict): dictionary with the expected node objects in FermentDB\n",
    "\n",
    "    example:\n",
    "        >>> get_collections_from_pasx(data=pasx_json_dict, config=main_parser_config.yaml)\n",
    "    '''\n",
    "    collections = {}\n",
    "    for c in config:\n",
    "        collections[c] = {}\n",
    "        # collections[c] = []\n",
    "        for a in config[c]:\n",
    "            if type(config[c][a]) != dict:\n",
    "                key = config[c][a].split('/')\n",
    "                value = get_from_nested_dict(data, key)\n",
    "                if a == '_key':\n",
    "                    value = str(value)\n",
    "                    if c == 'Project':  \n",
    "                        value = get_hash(value, prefix=\"P\")\n",
    "                    elif c == 'Batch_cell_culture':  \n",
    "                        value = get_hash(value, prefix=\"B\")\n",
    "                    elif c == 'User':  \n",
    "                        value = get_hash(value, prefix=\"U\")\n",
    "                    elif c == 'Country':  \n",
    "                        value = get_hash(value, prefix=\"Co\")\n",
    "                collections[c].update({a: value})\n",
    "                # collections[c].append({a: value})\n",
    "            else:\n",
    "                collections[c] = []\n",
    "                for nested_data in data[a]:\n",
    "                    nested_collection = {}\n",
    "                    for nested_a in config[c][a]:\n",
    "                        key = config[c][a][nested_a].split('/')\n",
    "                        value = get_from_nested_dict(nested_data, key)\n",
    "                        if nested_a == '_key':\n",
    "                            value = str(value)\n",
    "                        nested_collection.update({nested_a: value})\n",
    "                    collections[c].append(nested_collection)\n",
    "                    \n",
    "    return collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a704be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "848efb7c-d2a1-4022-95a4-8582b7ecb645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create node collections \n",
    "collections = get_collections_from_pasx(data, main_config)\n",
    "\n",
    "# print(collections[\"Project\"])\n",
    "# print(collections[\"User\"])\n",
    "# print(collections[\"Country\"])\n",
    "# print(collections[\"Batch_cell_culture\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e863d2a",
   "metadata": {},
   "source": [
    "### 3. Create edges collection and update node collections\n",
    "- Create a dictionary for edges collections.\n",
    "- Extract variables and phases from Run Collection and create node collections: initial_conditions, process_condition, Strain and phase_event. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f3f4753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Definitions\n",
    "\n",
    "def get_unique_json_from_list_of_dicts(d, unique_key='id'):\n",
    "    '''\n",
    "    Get a list of unique dictionaries based on a specified key.\n",
    "    \n",
    "    parameters:\n",
    "        d (list): list of dictionaries.\n",
    "        unique_key (str, optional): Key to determine uniqueness. Default to 'id'.\n",
    "    \n",
    "    return: \n",
    "        list: list of unique dictionaries. \n",
    "    \n",
    "    example:\n",
    "        >>> example_list = [\n",
    "        ...     {\"id\": 1, \"name\": \"Alice\"},\n",
    "        ...     {\"id\": 2, \"name\": \"Bob\"},\n",
    "        ...     {\"id\": 1, \"name\": \"Charlie\"},  # Duplicate id\n",
    "        ...     {\"id\": 3, \"name\": \"Alice\"}     # Duplicate name\n",
    "        ... ]\n",
    "        >>> get_unique_json_from_list_of_dicts(example_list)\n",
    "        #Intermediate step:\n",
    "        # {1: {\"id\": 1, \"name\": \"Alice\"}, 2: {\"id\": 2, \"name\": \"Bob\"}, 3: {\"id\": 3, \"name\": Alice}}.\n",
    "        [{'id': 1, 'name': 'Alice'}, {'id': 2, 'name': 'Bob'}, {'id': 3, 'name': 'Alice'}]\n",
    "    '''\n",
    "    unique_list = list({v[unique_key]:v for v in d}.values())\n",
    "    \n",
    "    return unique_list\n",
    "\n",
    "def get_run_conditions(collections, rconfig):\n",
    "    '''\n",
    "    Update node collections structure with nodes: initial condition, process conditions, fermenter, and strain.\n",
    "    Generate edges structure with collections: has_initial_condition, has_condition, cultures_strain, and uses_fermenter.  \n",
    "    \n",
    "    parameter:\n",
    "    - collections (dict): A dictionary containing collections of data.\n",
    "\n",
    "    returns:\n",
    "    - edges (dict): A dictionary containing edges data representing the relationships between runs, conditions, and strain.\n",
    "    '''\n",
    "    iconditions_collection = []\n",
    "    pconditions_collection = []\n",
    "    fermenter_collection = []\n",
    "    strain_collection = []\n",
    "    edges = {'has_initial_condition': {'edges':[],\n",
    "                                        'from_collection': ['Run'],\n",
    "                                        'to_collection': ['Initial_condition']},\n",
    "                'has_condition': {'edges': [],\n",
    "                                'from_collection': ['Run'],\n",
    "                                'to_collection': ['Process_condition']},\n",
    "                'has_measured_imodulon': {'edges':[],\n",
    "                              'from_collection': ['Run'],\n",
    "                              'to_collection':['iModulon']},\n",
    "                'cultures_strain': {'edges': [],\n",
    "                                'from_collection': ['Run'],\n",
    "                                'to_collection': ['Strain']},\n",
    "                'uses_fermenter': {'edges': [],\n",
    "                                'from_collection': ['Run'],\n",
    "                                'to_collection': ['Fermenter']},\n",
    "            }\n",
    "    \n",
    "    for run in collections['Run']:\n",
    "        run[\"_key\"] = run[\"name\"]+\"_\"+str(run['id'])\n",
    "        run[\"_key\"] = get_hash(run[\"_key\"], prefix=\"R\")\n",
    "        for variable in run['variables']:\n",
    "            variable[\"_key\"] = str(variable['name'])\n",
    "            variable[\"_key\"] = get_hash(variable[\"_key\"], prefix=\"C\")\n",
    "            data = variable.pop('data')\n",
    "            timestamps = variable.pop('timestamps')\n",
    "            unit = variable.pop('unit')\n",
    "            _ = variable.pop('categorical_data')\n",
    "            _ = variable.pop('raw_data')\n",
    "            _ = variable.pop('datetime_data')\n",
    "            _ = variable.pop('errors')\n",
    "            \n",
    "            if variable['name'] in rconfig['Run']:\n",
    "                if type(data) == list:\n",
    "                    data = data[0][0]\n",
    "                if variable['name'] == \"Strain Batch\":\n",
    "                    strain = '_'.join(data.split('-')[:1])\n",
    "                    strain_key = get_hash(strain, prefix=\"S\")\n",
    "                    strain_collection.append({'_key': strain_key,\n",
    "                                            'name': strain,\n",
    "                                            'rank': 'strain'})\n",
    "                    edges['cultures_strain']['edges'].append({'_from': f\"Run/{run['_key']}\",\n",
    "                                                            '_to': f'Strain/{strain_key}',\n",
    "                                                            'strain_batch': data})\n",
    "                run.update({rconfig['Run'][variable['name']]: data}) # Add to edge cultures strain and delete?\n",
    "            elif variable['name'] in rconfig['Fermenter']:\n",
    "                variable[\"_key\"] = get_hash(data, prefix=\"F\")\n",
    "                fermenter_collection.append({'_key': variable[\"_key\"],\n",
    "                                             'name': data})\n",
    "                edges['uses_fermenter']['edges'].append({'_from': f\"Run/{run['_key']}\",\n",
    "                           '_to': f\"Fermenter/{variable['_key']}\"})\n",
    "            elif variable['name'] in rconfig['Initial_condition']:\n",
    "                iconditions_collection.append(variable)\n",
    "                edges['has_initial_condition']['edges'].append({'_from': f\"Run/{run['_key']}\",\n",
    "                           '_to': f\"Initial_condition/{variable['_key']}\",\n",
    "                           'data': data,\n",
    "                           'unit': unit})\n",
    "            elif '_RNAseq' in variable['name']:\n",
    "                if not all(v == 0 for v in data):\n",
    "                    variable['name'] = ' '.join(variable['name'].replace('_RNAseq', '').split('_'))\n",
    "                    variable[\"_key\"] = get_hash(variable[\"name\"], prefix=\"iM\")\n",
    "                    edges['has_measured_imodulon']['edges'].append({'_from': f\"Run/{run['_key']}\",\n",
    "                                                           '_to': f\"iModulon/{variable['_key']}\",\n",
    "                                                           'data': data,\n",
    "                                                           'timestamps': timestamps})\n",
    "            else:\n",
    "                pconditions_collection.append(variable)\n",
    "                if not all(v == 0 for v in data):\n",
    "                    edges['has_condition']['edges'].append({'_from': f\"Run/{run['_key']}\",\n",
    "                            '_to': f\"Process_condition/{variable['_key']}\",\n",
    "                            'data': data,\n",
    "                            'unit': unit,\n",
    "                            'timestamps': timestamps})\n",
    "        del run['variables']\n",
    "    \n",
    "    iconditions_collection = get_unique_json_from_list_of_dicts(d=iconditions_collection, \n",
    "                                                                    unique_key='_key')\n",
    "    pconditions_collection = get_unique_json_from_list_of_dicts(d=pconditions_collection, \n",
    "                                                                    unique_key='_key')\n",
    "    fermenter_collection = get_unique_json_from_list_of_dicts(d=fermenter_collection, \n",
    "                                                                    unique_key='_key')\n",
    "    strain_collection = get_unique_json_from_list_of_dicts(d=strain_collection, \n",
    "                                                                    unique_key='_key')\n",
    "    collections['Initial_condition'] = iconditions_collection\n",
    "    collections['Process_condition'] = pconditions_collection\n",
    "    collections['Fermenter'] = fermenter_collection\n",
    "    collections['Strain'] = strain_collection\n",
    "    \n",
    "    return edges\n",
    "\n",
    "def get_run_phases(collections):\n",
    "    '''\n",
    "    Retrieves phases data from Run collection and create Phase_event node collection and has_phase edge collection.  \n",
    "\n",
    "    parameter:\n",
    "    - collections (dict): A dictionary containing collections of data.\n",
    "\n",
    "    returns:\n",
    "    - dict: A dictionary containing edges data representing the relationships between runs and phases.\n",
    "    '''\n",
    "    phases_collection = []\n",
    "    edges = {'has_phase': {'edges':[],\n",
    "                           'from_collection': ['Run'],\n",
    "                           'to_collection':['Phase_event']}}\n",
    "\n",
    "    for run in collections['Run']:\n",
    "        for phase in run['phases']:\n",
    "            phase[\"_key\"] = phase['name']\n",
    "            phase[\"_key\"] = get_hash(phase[\"_key\"], prefix=\"PH\")\n",
    "            attributes = {\"event_start\": phase.pop(\"start\"),\n",
    "                          \"event_end\": phase.pop(\"end\"),\n",
    "                          \"comment\": phase.pop(\"comment\"),\n",
    "                          \"created_by\": phase.pop(\"created_by\"),\n",
    "                          \"start\": phase.pop(\"relative_start\"),\n",
    "                          \"end\": phase.pop(\"relative_end\")}\n",
    "            attributes.update({'_from': f\"Run/{run['_key']}\",\n",
    "                           '_to': f\"Phase_event/{phase['_key']}\"})\n",
    "            phases_collection.append(phase)\n",
    "            edges['has_phase']['edges'].append(attributes)\n",
    "            phases_collection = get_unique_json_from_list_of_dicts(d=phases_collection, \n",
    "                                                                    unique_key='_key')\n",
    "        del run['phases']\n",
    "    \n",
    "    collections['Phase_event'] = phases_collection\n",
    "\n",
    "    return edges\n",
    "    \n",
    "\n",
    "def generate_project_edges(collections, edges):\n",
    "    '''\n",
    "    Generate edges between collections: has_batch, created_by, and has_run; between nodes: user, project and batch_cell_culture nodes collections.\n",
    "    \n",
    "    parameter: \n",
    "        collections (dict): A dictionary containing collections as keys and their corresponding documents as values.\n",
    "        edges(dict): A dictionary representing edges between collections.\n",
    "    \n",
    "    returns:\n",
    "        None: This function updates the 'edges' dictionary in place.\n",
    "    \n",
    "    example:\n",
    "        collections = {\n",
    "        'Project': {'_key': 'project_key', 'creation_time': '2024-05-01T12:00:00Z'},\n",
    "        'User': {'_key': 'user_key'},\n",
    "        'Batch_cell_culture': {'_key': 'batch_key'},\n",
    "        'Run': [{'_key': 'run_key1'}, {'_key': 'run_key2'}, ...]\n",
    "        }\n",
    "        edges = {}\n",
    "        generate_project_edges(collections, edges)\n",
    "        # edges will be updated with edges between collections.\n",
    "    '''\n",
    "   \n",
    "    # edges.update({'has_batch': {'edges':[], \n",
    "    #                             'from_collection': ['Project'],\n",
    "    #                             'to_collection':['Batch_cell_culture']},\n",
    "    #             'created_by': {'edges':[],\n",
    "    #                             'from_collection': ['Project'],\n",
    "    #                             'to_collection':['User']},\n",
    "    #             'has_run': {'edges':[], \n",
    "    #                         'from_collection': ['Batch_cell_culture'],\n",
    "    #                         'to_collection':['Run']}\n",
    "    #                             })\n",
    "    \n",
    "    # for user in collections['User']:\n",
    "    #     for batch in collections['Batch_cell_culture']:\n",
    "    #         for project in collections['Project']:\n",
    "    #             if '_key' in project:\n",
    "    #                 edges['has_batch']['edges'].append({'_from': f\"Project/{project['_key']}\",\n",
    "    #                                                     '_to': f\"Batch_cell_culture/{batch['_key']}\"})\n",
    "    #                 edges['created_by']['edges'].append({'_from': f\"Project/{project['_key']}\",\n",
    "    #                                                     '_to': f\"User/{user['_key']}\"})\n",
    "    project = collections['Project']\n",
    "    user = collections['User']\n",
    "    batch = collections['Batch_cell_culture']\n",
    "\n",
    "    edges.update({'has_batch': {'edges':[{'_from': f\"Project/{project['_key']}\",\n",
    "                                          '_to': f\"Batch_cell_culture/{batch['_key']}\"}], \n",
    "                                'from_collection': ['Project'],\n",
    "                                'to_collection':['Batch_cell_culture']},\n",
    "                  'created_by': {'edges':[{'_from': f\"Project/{project['_key']}\",\n",
    "                                          '_to': f\"User/{user['_key']}\",\n",
    "                                          'creation_date': project['creation_time']}],\n",
    "                                'from_collection': ['Project'],\n",
    "                                'to_collection':['User']}})\n",
    "    edges.update({'has_run': {'edges':[], \n",
    "                              'from_collection': ['Batch_cell_culture'],\n",
    "                                'to_collection':['Run']}})\n",
    "    for run in collections['Run']:\n",
    "        edges['has_run']['edges'].append({'_from': f\"Batch_cell_culture/{batch['_key']}\",\n",
    "                                          '_to': f\"Run/{run['_key']}\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e59fda",
   "metadata": {},
   "source": [
    "### 4. Create iModulon node and edges collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ac1d797",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Define iModulon function \n",
    "def get_imodulon_collection(organism, dataset, table_path):\n",
    "    '''\n",
    "    Process iModulon data to generate a collection for a given organism and dataset. \n",
    "    - Reads data from a CSV file into a pandas DataFrame. \n",
    "    - Adds additional fields such as a key column from hashing name column, and creates linkout column by constructing URLs to generate individual links for each iModulon entry.\n",
    "    - Processes dataset by handling misisng values and dropping the 'k' column as it is no loger needed (values areincorporated into the linkout column) \n",
    "\n",
    "    parameters:\n",
    "        organism (str): The name of the organism (e.g., 'e_coli').\n",
    "        dataset (str): The name of the dataset (e.g., 'precise1k').\n",
    "        table_path (str): The file path to the CSV file containing the iModulon data (e.g., '/path/to/iM_table.csv').\n",
    "\n",
    "    return:\n",
    "        data_dict: A list of dictionaries representing processed iModulon data\n",
    "    '''\n",
    "    imodulon_link = f'https://imodulondb.org/iModulon.html?organism={organism}&dataset={dataset}&k='\n",
    "    data = pd.read_csv(table_path, sep=',', header=0)\n",
    "    data['_key'] = data['name'].apply(lambda n: get_hash(n, prefix=\"iM\"))\n",
    "    data['linkout'] = data['k'].apply(lambda k: imodulon_link+str(k))\n",
    "    data = data.fillna('NaN').drop('k', axis=1)\n",
    "    data_dict = data.to_dict(orient='records')\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2282c406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate iModulon collection\n",
    "collections['iModulon'] = []\n",
    "for organism in imodulon_files:\n",
    "    for dataset in imodulon_files[organism]:\n",
    "        imodulon_path = imodulon_files[organism][dataset]\n",
    "        collections['iModulon'].extend(get_imodulon_collection(organism=organism, dataset=dataset, table_path=imodulon_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3667915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create edges with conditions collections, phases collections and project edges\n",
    "\n",
    "edges = get_run_conditions(collections, var_config)\n",
    "edges.update(get_run_phases(collections))\n",
    "generate_project_edges(collections, edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ab9977",
   "metadata": {},
   "source": [
    "### 5. Create species node and edge collections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47904fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/59/fbtwqg3d2r97w0gc059ff5qh0000gp/T/ipykernel_8522/3504519149.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  strain_mapping = {r[0]: {'name': r[1], 'taxid':r[2]} for i,r in strain_mapping.iterrows()}\n"
     ]
    }
   ],
   "source": [
    "with open(strain_mapping_path, 'r') as strain_file:\n",
    "    strain_mapping = pd.read_csv(strain_file, sep=',')\n",
    "\n",
    "# From df to dict\n",
    "strain_mapping = {r[0]: {'name': r[1], 'taxid':r[2]} for i,r in strain_mapping.iterrows()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0055c6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a Species collection: nodes and edges\n",
    "species = []\n",
    "\n",
    "# Create edge 'belongs_to'\n",
    "if 'belongs_to' not in edges:\n",
    "    edges['belongs_to'] = {\n",
    "        'edges': [],\n",
    "        'from_collection': ['Strain'],\n",
    "        'to_collection': ['Species']\n",
    "    }\n",
    "\n",
    "for strain in collections['Strain']:\n",
    "    strain_key = strain['_key']\n",
    "    name = strain['name']\n",
    "    if name in strain_mapping:\n",
    "        organism = strain_mapping[name]['name']\n",
    "        taxid = str(strain_mapping[name]['taxid'])\n",
    "        species.append({\n",
    "            '_key': taxid,\n",
    "            'name': organism,\n",
    "            'rank': 'species'\n",
    "        })\n",
    "        edges['belongs_to']['edges'].append({\n",
    "            '_from': f'Strain/{strain_key}',\n",
    "            '_to': f'Species/{taxid}'\n",
    "        })\n",
    "\n",
    "collections['Species'] = get_unique_json_from_list_of_dicts(d=species,\n",
    "                                                            unique_key='_key')                               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec2777b",
   "metadata": {},
   "source": [
    "### 6. Create institution node collection and edges collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39c25ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an Institution node collection with a document at its edges\n",
    "if 'Institution' not in collections:\n",
    "        institution_key = get_hash(\"NNFCB\", prefix=\"I\")\n",
    "        collections['Institution'] = [{'_key': institution_key,\n",
    "                                'name': 'NNFCB - Novo Nordisk Foundation Center for Biosustainability (DTU Biosustain)',\n",
    "                                'address': 'Building 220, Kemitorvet. 2800 Kgs. Lyngby',\n",
    "                                'email': 'biosustain@biosustain.dtu.dk',\n",
    "                                'phone_number':'+45 45 25 80 00'\n",
    "                                }]\n",
    "\n",
    "project = collections['Project']\n",
    "user = collections['User']\n",
    "country = collections['Country']\n",
    "\n",
    "edges.update({'created_at': {'edges':[{'_from': f\"Project/{project['_key']}\",\n",
    "                                          '_to': f\"Institution/{institution_key}\"}], \n",
    "                                'from_collection': ['Project'],\n",
    "                                'to_collection':['Institution']},\n",
    "                'works_at': {'edges':[{'_from': f\"User/{user['_key']}\",\n",
    "                                          '_to': f\"Institution/{institution_key}\"}],\n",
    "                                'from_collection': ['User'],\n",
    "                                'to_collection':['Institution']},\n",
    "                'from': {'edges':[{'_from': f\"Institution/{institution_key}\",\n",
    "                                          '_to': f\"Country/{country['_key']}\",\n",
    "                                          'creation_date': project['creation_time']}],\n",
    "                                'from_collection': ['Institution'],\n",
    "                                'to_collection':['Country']}})\n",
    "\n",
    "# ## Create 'created_at' edge\n",
    "# if 'created_at' not in edges:\n",
    "#         edges['created_at'] = {'edges': [],\n",
    "#                                 'from_collection': ['Project'],\n",
    "#                                 'to_collection': ['Institution']}\n",
    "\n",
    "# for project in collections['Project']:\n",
    "#         print(f\"Project: {project}\")\n",
    "#         project_key = int(project[\"_key\"])\n",
    "#         edges['created_at']['edges'].append({\n",
    "#                 '_from': f\"Project/{project_key}\",\n",
    "#                 '_to': f\"Institution/{institution_key}\"\n",
    "#         })\n",
    "\n",
    "# ## Create 'works_at' edge\n",
    "# if 'works_at' not in edges:\n",
    "#         edges['works_at'] = {'edges':[], \n",
    "#                                 'from_collection': ['User'],\n",
    "#                                 'to_collection': ['Institution']}\n",
    "\n",
    "# for user in collections['User']:\n",
    "#         user_key = int(user[\"_key\"])\n",
    "#         edges['works_at']['edges'].append({\n",
    "#                 '_from': f\"User/{user_key}\",\n",
    "#                 '_to': f\"Institution/{institution_key}\"\n",
    "#         })\n",
    "\n",
    "\n",
    "\n",
    "# ## Create 'from' edge\n",
    "# if 'from' not in edges:\n",
    "#         edges['from'] = {'edges': [],\n",
    "#                                 'from_collection': ['Institution'],\n",
    "#                                 'to_collection': ['Country']}\n",
    "\n",
    "# for country in collections['Country']:\n",
    "#         country_key = int(country[\"_key\"])\n",
    "#         edges['from']['edges'].append({\n",
    "#                 '_from': f\"Institution/{institution_key}\",\n",
    "#                 '_to': f\"Country/{country_key}\"\n",
    "#         })\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9ac80f",
   "metadata": {},
   "source": [
    "### 7. Output nodes and edges collections as two JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6c083fa-6595-47fa-98ce-8c9e6303ced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output nodes collections \n",
    "os.makedirs(os.path.dirname(nodes_path), exist_ok = True)\n",
    "nodes_str = json.dumps(collections)\n",
    "with open(nodes_path, 'w') as out:\n",
    "    out.write(nodes_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc77c8fc-1de8-4d62-aa43-6e2671b3d459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output edges collections\n",
    "os.makedirs(os.path.dirname(edges_path), exist_ok = True)\n",
    "edges_str = json.dumps(edges)\n",
    "with open(edges_path, 'w') as out:\n",
    "    out.write(edges_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fermentdb_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
