{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea153251",
   "metadata": {},
   "source": [
    "# Parser for PAS-X Data File\n",
    "This notebook focuses on parsing data from PAS-X software to extract and model/organize high-cell density fermentation data.  \n",
    "\n",
    "PAS-X file contains data about one project which contains several batches of different runs, and each run contains data of several features.   \n",
    "\n",
    "The <b>primary objective</b> is to parse the PAS-X data file with configs files such as parser_config and run_config in order to generate document structures (JSON) for our graph, concretely node documents and edge documents such as: project, batch_cell_cultures, run, strain, species, initial_conditions and process_conditions.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3b96a6a9-cc90-46f7-9a29-ed9e73623d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Install dependencies\n",
    "#!pip install pandas\n",
    "#!pip install pyarango"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33ae25ad-ad5c-4bff-957c-1d9a124d7864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Import modules\n",
    "import os\n",
    "import yaml\n",
    "import json\n",
    "import hashlib\n",
    "from functools import reduce\n",
    "import operator\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30c3e111-55d5-4282-a0eb-515d579d85d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define file paths\n",
    "data_dir = '../data'\n",
    "data_path = os.path.join(data_dir, \"20240328_dataset for ambrDB_DDBproject.json\")\n",
    "config_dir = '../config'\n",
    "config_path = os.path.join(config_dir, 'parser_config.yaml')\n",
    "run_config_path = os.path.join(config_dir, 'run_config.yaml')\n",
    "strain_mapping_path = os.path.join(data_dir, \"strains_organism.csv\")\n",
    "output_dir = '../output'\n",
    "nodes_path = os.path.join(output_dir, \"fermentdb_nodes_full.json\")\n",
    "edges_path = os.path.join(output_dir, \"fermentdb_edges_full.json\")\n",
    "imodulon_files = {'e_coli': {'precise1k': os.path.join(data_dir, 'iM_table.csv')}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a5b857",
   "metadata": {},
   "source": [
    "### 1. Load data and config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e34617eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['end', 'created_by', 'editable', 'unit_operations', 'workflow', 'creation_time', 'project', 'description', 'status', 'name', 'event_names', 'key_variable', 'id', 'type', 'result_notes', 'progress', 'country', 'manager', 'trending_settings', 'deletable', 'modification_time', 'batch_phase_names', 'tags', 'start', 'departments', 'editable_plots', 'sites', 'batches'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load PASX data file\n",
    "with open(data_path, 'r') as dbfile:\n",
    "    data = json.load(dbfile)\n",
    "\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42640478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Project': {'_key': 'project',\n",
       "  'id': 'project',\n",
       "  'name': 'name',\n",
       "  'description': 'description',\n",
       "  'progress': 'progress',\n",
       "  'status': 'status',\n",
       "  'deletable': 'deletable',\n",
       "  'editable': 'editable',\n",
       "  'type': 'type',\n",
       "  'creation_time': 'creation_time',\n",
       "  'tags': 'tags',\n",
       "  'modification_time': 'modification_time',\n",
       "  'start': 'start',\n",
       "  'end': 'end'},\n",
       " 'Country': {'_key': 'country', 'id': 'country', 'name': 'country'},\n",
       " 'User': {'_key': 'manager/username',\n",
       "  'id': 'manager/username',\n",
       "  'name': 'manager/first_name',\n",
       "  'surname': 'manager/last_name'},\n",
       " 'Batch_cell_culture': {'_key': 'id', 'id': 'id', 'name': 'name'},\n",
       " 'Run': {'batches': {'id': 'id',\n",
       "   'name': 'name',\n",
       "   'description': 'description',\n",
       "   'creation_time': 'creation_time',\n",
       "   'modification_time': 'modification_time',\n",
       "   'batch_start': 'batch_start',\n",
       "   'batch_end': 'batch_end',\n",
       "   'first_timestamp': 'first_timestamp',\n",
       "   'last_timestamp': 'last_timestamp',\n",
       "   'variables': 'variables',\n",
       "   'phases': 'phases'}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load parser_config.yaml\n",
    "with open(config_path, 'r') as cfile:\n",
    "    config = yaml.load(cfile, Loader=yaml.SafeLoader)\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d0c465e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Run': {'id': 'id',\n",
       "  'Culture Type': 'culture_type',\n",
       "  'Seed': 'seed',\n",
       "  'Sample ID': 'sample_id',\n",
       "  'Experiment': 'experiment',\n",
       "  'Replicate #': 'replicate_number',\n",
       "  'Strain Batch': 'strain_batch',\n",
       "  'Container ID (calculated)': 'container_id',\n",
       "  'Control?': 'is_control',\n",
       "  'Comments': 'comments',\n",
       "  'Inducer': 'inducer',\n",
       "  'Volume Unit_INDUCTION': 'volume_unit_induction',\n",
       "  'Condition': 'condition'},\n",
       " 'Fermenter': {'Container Type': 'name'},\n",
       " 'Initial_condition': {'SOP': 'SOP',\n",
       "  'Aeration Gas Type': 'aeration_gas_type',\n",
       "  'Aeration Profile': 'aeration_profile',\n",
       "  'Maximum Aeration (slpm)': 'maximum_aeration_slpm',\n",
       "  'Minimum Aeration (slpm)': 'minimum_aeration_slpm',\n",
       "  'Maximum Stirring or Shaking Speed (rpm)': 'maximum_stirring_speed_rpm',\n",
       "  'Minimum Stirring or Shaking Speed (rpm)': 'minimum_stirring_speed_rpm',\n",
       "  'DO Control Setpoint (%)': 'DO_control_setpoint_percentage',\n",
       "  'DO Control Cascade Level 1': 'DO_control_cascade_level1',\n",
       "  'DO Control Cascade Level 2': 'DO_control_cascade_level2',\n",
       "  'DO Control Cascade Level 3': 'DO_control_cascade_level3',\n",
       "  'Starting OD': 'starting_OD',\n",
       "  'Feed #1 Profile': 'feed_1_profile',\n",
       "  'Feed Medium #1': 'feed_medium_1',\n",
       "  'Feed Medium #2': 'feed_medium_2',\n",
       "  'pH Setpoint': 'pH_setpoint',\n",
       "  'pH Control Base Solution': 'ph_control_base_solution',\n",
       "  'pH Control Acid Solution': 'ph_control_acid_solution',\n",
       "  'Temperature Setpoint (C)': 'temperature_setpoint_celsius',\n",
       "  'Main Culture ID': 'main_culture_id',\n",
       "  'Initial Culture VolumeNone': 'initial_volume',\n",
       "  'Culture Volume Unit': 'culture_volume_unit',\n",
       "  'Base Medium': 'base_medium'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load run_config.yaml\n",
    "with open(run_config_path, 'r') as cfile:\n",
    "    rconfig = yaml.load(cfile, Loader=yaml.SafeLoader)\n",
    "\n",
    "rconfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29be854",
   "metadata": {},
   "source": [
    "### 2. Create node collections dictionary structure\n",
    "Create a dictionary structure for nodes collections with parser_config file and PASX data file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03a4becc-79a7-4191-a505-decba440eb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Definitions\n",
    "\n",
    "def get_from_nested_dict(data_dict:dict, map_list:list):\n",
    "    '''\n",
    "    Extracts value from a nested dictionary given a list of keys (different levels).\n",
    "\n",
    "    parameters:\n",
    "        data_dict (dict): dictionary structure \n",
    "        map_list (list): list of nested keys\n",
    "\n",
    "    return:\n",
    "        nested_value: nested value given the provided list of keys\n",
    "\n",
    "    example:\n",
    "        >>> data_dict = {'a': {'b': {'c': 5}}}\n",
    "        >>> value = get_from_nested_dict(data_dict=data_dict, map_list=['a', 'b', 'c'])\n",
    "        >>> print(value)\n",
    "        5\n",
    "    '''\n",
    "\n",
    "    nested_value = None\n",
    "    try:\n",
    "        nested_value = reduce(operator.getitem, map_list, data_dict)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return nested_value\n",
    "\n",
    "def get_hash(key, prefix=\"\"):\n",
    "    '''\n",
    "    Get a hash value for a given key:\n",
    "    Hash a string using SHA-1, before encode key string into bytes using the UTF-8 encoding, as the sha1() expects bytes as input. \n",
    "    Convert the binary hash value into a hexadecimal string and then into an 8-digit integer.\n",
    "    Convert it to a string and add a prefix.\n",
    "\n",
    "    parameters:\n",
    "        key (str): Input string to be hashed.\n",
    "        prefix (str, optional): Prefix to prepend to the hash value. Defaults to \"\".\n",
    "\n",
    "    return:\n",
    "        str: Hash value.\n",
    "\n",
    "    example:\n",
    "        >>> input_key = \"example_key\"\n",
    "        >>> get_hash(input_key, prefix=\"HASH_\")\n",
    "        'HASH_45200d86'\n",
    "    '''\n",
    "    hkey = str(int(hashlib.sha1(key.encode(\"utf-8\")).hexdigest(),16) % (10 ** 8))\n",
    "    hkey = f\"{prefix}{hkey}\"\n",
    "    \n",
    "    return hkey\n",
    "\n",
    "\n",
    "def get_collections_from_pasx(data: dict, config: dict) -> dict:\n",
    "    '''\n",
    "    This function creates a dictionary with the node collections expected\n",
    "    in FermentDB. It requires a dictionary with the data exported from PASX\n",
    "    in json format, and a configuration file that specifies the mapping between\n",
    "    PASX and FermentDB structure. See example in '/config/parser_config.yaml'\n",
    "\n",
    "    parameters:\n",
    "        data (dict): dictionary with the data read from PASX in json format\n",
    "        config (dict): mapping configuration to adapt to FermentDB structure\n",
    "\n",
    "    return:\n",
    "        collections (dict): dictionary with the expected node objects in FermentDB\n",
    "\n",
    "    example:\n",
    "        >>> get_collections_from_pasx(data=pasx_json_dict, config=parser_config.yaml)\n",
    "    '''\n",
    "    collections = {}\n",
    "    for c in config:\n",
    "        collections[c] = {}\n",
    "        # collections[c] = []\n",
    "        for a in config[c]:\n",
    "            if type(config[c][a]) != dict:\n",
    "                key = config[c][a].split('/')\n",
    "                value = get_from_nested_dict(data, key)\n",
    "                if a == '_key':\n",
    "                    value = str(value)\n",
    "                    if c == 'Project':  \n",
    "                        value = get_hash(value, prefix=\"P\")\n",
    "                    elif c == 'Batch_cell_culture':  \n",
    "                        value = get_hash(value, prefix=\"B\")\n",
    "                    elif c == 'User':  \n",
    "                        value = get_hash(value, prefix=\"U\")\n",
    "                    elif c == 'Country':  \n",
    "                        value = get_hash(value, prefix=\"Co\")\n",
    "                collections[c].update({a: value})\n",
    "                # collections[c].append({a: value})\n",
    "            else:\n",
    "                collections[c] = []\n",
    "                for nested_data in data[a]:\n",
    "                    nested_collection = {}\n",
    "                    for nested_a in config[c][a]:\n",
    "                        key = config[c][a][nested_a].split('/')\n",
    "                        value = get_from_nested_dict(nested_data, key)\n",
    "                        if nested_a == '_key':\n",
    "                            value = str(value)\n",
    "                        nested_collection.update({nested_a: value})\n",
    "                    collections[c].append(nested_collection)\n",
    "                    \n",
    "    return collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "848efb7c-d2a1-4022-95a4-8582b7ecb645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create node collections \n",
    "collections = get_collections_from_pasx(data, config)\n",
    "\n",
    "# print(collections[\"Project\"])\n",
    "# print(collections[\"User\"])\n",
    "# print(collections[\"Country\"])\n",
    "# print(collections[\"Batch_cell_culture\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e863d2a",
   "metadata": {},
   "source": [
    "### 3. Create edges collection and update node collections\n",
    "- Create a dictionary for edges collections.\n",
    "- Extract variables and phases from Run Collection and create node collections: initial_conditions, process_condition, Strain and phase_event. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f3f4753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Definitions\n",
    "\n",
    "def get_unique_json_from_list_of_dicts(d, unique_key='id'):\n",
    "    '''\n",
    "    Get a list of unique dictionaries based on a specified key.\n",
    "    \n",
    "    parameters:\n",
    "        d (list): list of dictionaries.\n",
    "        unique_key (str, optional): Key to determine uniqueness. Default to 'id'.\n",
    "    \n",
    "    return: \n",
    "        list: list of unique dictionaries. \n",
    "    \n",
    "    example:\n",
    "        >>> example_list = [\n",
    "        ...     {\"id\": 1, \"name\": \"Alice\"},\n",
    "        ...     {\"id\": 2, \"name\": \"Bob\"},\n",
    "        ...     {\"id\": 1, \"name\": \"Charlie\"},  # Duplicate id\n",
    "        ...     {\"id\": 3, \"name\": \"Alice\"}     # Duplicate name\n",
    "        ... ]\n",
    "        >>> get_unique_json_from_list_of_dicts(example_list)\n",
    "        #Intermediate step:\n",
    "        # {1: {\"id\": 1, \"name\": \"Alice\"}, 2: {\"id\": 2, \"name\": \"Bob\"}, 3: {\"id\": 3, \"name\": Alice}}.\n",
    "        [{'id': 1, 'name': 'Alice'}, {'id': 2, 'name': 'Bob'}, {'id': 3, 'name': 'Alice'}]\n",
    "    '''\n",
    "    unique_list = list({v[unique_key]:v for v in d}.values())\n",
    "    \n",
    "    return unique_list\n",
    "\n",
    "def get_run_conditions(collections, rconfig):\n",
    "    '''\n",
    "    Update node collections structure with nodes: initial condition, process conditions, fermenter, and strain.\n",
    "    Generate edges structure with collections: has_initial_condition, has_condition, cultures_strain, and uses_fermenter.  \n",
    "    \n",
    "    parameter:\n",
    "    - collections (dict): A dictionary containing collections of data.\n",
    "\n",
    "    returns:\n",
    "    - edges (dict): A dictionary containing edges data representing the relationships between runs, conditions, and strain.\n",
    "    '''\n",
    "    iconditions_collection = []\n",
    "    pconditions_collection = []\n",
    "    fermenter_collection = []\n",
    "    strain_collection = []\n",
    "    edges = {'has_initial_condition': {'edges':[],\n",
    "                                        'from_collection': ['Run'],\n",
    "                                        'to_collection': ['Initial_condition']},\n",
    "                'has_condition': {'edges': [],\n",
    "                                'from_collection': ['Run'],\n",
    "                                'to_collection': ['Process_condition']},\n",
    "                'has_measured_imodulon': {'edges':[],\n",
    "                              'from_collection': ['Run'],\n",
    "                              'to_collection':['iModulon']},\n",
    "                'cultures_strain': {'edges': [],\n",
    "                                'from_collection': ['Run'],\n",
    "                                'to_collection': ['Strain']},\n",
    "                'uses_fermenter': {'edges': [],\n",
    "                                'from_collection': ['Run'],\n",
    "                                'to_collection': ['Fermenter']},\n",
    "            }\n",
    "    \n",
    "    for run in collections['Run']:\n",
    "        run[\"_key\"] = run[\"name\"]+\"_\"+str(run['id'])\n",
    "        run[\"_key\"] = get_hash(run[\"_key\"], prefix=\"R\")\n",
    "        for variable in run['variables']:\n",
    "            variable[\"_key\"] = str(variable['name'])\n",
    "            variable[\"_key\"] = get_hash(variable[\"_key\"], prefix=\"C\")\n",
    "            data = variable.pop('data')\n",
    "            timestamps = variable.pop('timestamps')\n",
    "            unit = variable.pop('unit')\n",
    "            _ = variable.pop('categorical_data')\n",
    "            _ = variable.pop('raw_data')\n",
    "            _ = variable.pop('datetime_data')\n",
    "            _ = variable.pop('errors')\n",
    "            \n",
    "            if variable['name'] in rconfig['Run']:\n",
    "                if type(data) == list:\n",
    "                    data = data[0][0]\n",
    "                if variable['name'] == \"Strain Batch\":\n",
    "                    strain = '_'.join(data.split('-')[:1])\n",
    "                    strain_key = get_hash(strain, prefix=\"S\")\n",
    "                    strain_collection.append({'_key': strain_key,\n",
    "                                            'name': strain,\n",
    "                                            'rank': 'strain'})\n",
    "                    edges['cultures_strain']['edges'].append({'_from': f\"Run/{run['_key']}\",\n",
    "                                                            '_to': f'Strain/{strain_key}',\n",
    "                                                            'strain_batch': data})\n",
    "                run.update({rconfig['Run'][variable['name']]: data}) # Add to edge cultures strain and delete?\n",
    "            elif variable['name'] in rconfig['Fermenter']:\n",
    "                variable[\"_key\"] = get_hash(data, prefix=\"F\")\n",
    "                fermenter_collection.append({'_key': variable[\"_key\"],\n",
    "                                             'name': data})\n",
    "                edges['uses_fermenter']['edges'].append({'_from': f\"Run/{run['_key']}\",\n",
    "                           '_to': f\"Fermenter/{variable['_key']}\"})\n",
    "            elif variable['name'] in rconfig['Initial_condition']:\n",
    "                iconditions_collection.append(variable)\n",
    "                edges['has_initial_condition']['edges'].append({'_from': f\"Run/{run['_key']}\",\n",
    "                           '_to': f\"Initial_condition/{variable['_key']}\",\n",
    "                           'data': data,\n",
    "                           'unit': unit})\n",
    "            elif '_RNAseq' in variable['name']:\n",
    "                if not all(v == 0 for v in data):\n",
    "                    variable['name'] = ' '.join(variable['name'].replace('_RNAseq', '').split('_'))\n",
    "                    variable[\"_key\"] = get_hash(variable[\"name\"], prefix=\"iM\")\n",
    "                    edges['has_measured_imodulon']['edges'].append({'_from': f\"Run/{run['_key']}\",\n",
    "                                                           '_to': f\"iModulon/{variable['_key']}\",\n",
    "                                                           'data': data,\n",
    "                                                           'timestamps': timestamps})\n",
    "            else:\n",
    "                pconditions_collection.append(variable)\n",
    "                if not all(v == 0 for v in data):\n",
    "                    edges['has_condition']['edges'].append({'_from': f\"Run/{run['_key']}\",\n",
    "                            '_to': f\"Process_condition/{variable['_key']}\",\n",
    "                            'data': data,\n",
    "                            'unit': unit,\n",
    "                            'timestamps': timestamps})\n",
    "        del run['variables']\n",
    "    \n",
    "    iconditions_collection = get_unique_json_from_list_of_dicts(d=iconditions_collection, \n",
    "                                                                    unique_key='_key')\n",
    "    pconditions_collection = get_unique_json_from_list_of_dicts(d=pconditions_collection, \n",
    "                                                                    unique_key='_key')\n",
    "    fermenter_collection = get_unique_json_from_list_of_dicts(d=fermenter_collection, \n",
    "                                                                    unique_key='_key')\n",
    "    strain_collection = get_unique_json_from_list_of_dicts(d=strain_collection, \n",
    "                                                                    unique_key='_key')\n",
    "    collections['Initial_condition'] = iconditions_collection\n",
    "    collections['Process_condition'] = pconditions_collection\n",
    "    collections['Fermenter'] = fermenter_collection\n",
    "    collections['Strain'] = strain_collection\n",
    "    \n",
    "    return edges\n",
    "\n",
    "def get_run_phases(collections):\n",
    "    '''\n",
    "    Retrieves phases data from Run collection and create Phase_event node collection and has_phase edge collection.  \n",
    "\n",
    "    parameter:\n",
    "    - collections (dict): A dictionary containing collections of data.\n",
    "\n",
    "    returns:\n",
    "    - dict: A dictionary containing edges data representing the relationships between runs and phases.\n",
    "    '''\n",
    "    phases_collection = []\n",
    "    edges = {'has_phase': {'edges':[],\n",
    "                           'from_collection': ['Run'],\n",
    "                           'to_collection':['Phase_event']}}\n",
    "\n",
    "    for run in collections['Run']:\n",
    "        for phase in run['phases']:\n",
    "            phase[\"_key\"] = phase['name']\n",
    "            phase[\"_key\"] = get_hash(phase[\"_key\"], prefix=\"PH\")\n",
    "            attributes = {\"event_start\": phase.pop(\"start\"),\n",
    "                          \"event_end\": phase.pop(\"end\"),\n",
    "                          \"comment\": phase.pop(\"comment\"),\n",
    "                          \"created_by\": phase.pop(\"created_by\"),\n",
    "                          \"start\": phase.pop(\"relative_start\"),\n",
    "                          \"end\": phase.pop(\"relative_end\")}\n",
    "            attributes.update({'_from': f\"Run/{run['_key']}\",\n",
    "                           '_to': f\"Phase_event/{phase['_key']}\"})\n",
    "            phases_collection.append(phase)\n",
    "            edges['has_phase']['edges'].append(attributes)\n",
    "            phases_collection = get_unique_json_from_list_of_dicts(d=phases_collection, \n",
    "                                                                    unique_key='_key')\n",
    "        del run['phases']\n",
    "    \n",
    "    collections['Phase_event'] = phases_collection\n",
    "\n",
    "    return edges\n",
    "    \n",
    "\n",
    "def generate_project_edges(collections, edges):\n",
    "    '''\n",
    "    Generate edges between collections: has_batch, created_by, and has_run; between nodes: user, project and batch_cell_culture nodes collections.\n",
    "    \n",
    "    parameter: \n",
    "        collections (dict): A dictionary containing collections as keys and their corresponding documents as values.\n",
    "        edges(dict): A dictionary representing edges between collections.\n",
    "    \n",
    "    returns:\n",
    "        None: This function updates the 'edges' dictionary in place.\n",
    "    \n",
    "    example:\n",
    "        collections = {\n",
    "        'Project': {'_key': 'project_key', 'creation_time': '2024-05-01T12:00:00Z'},\n",
    "        'User': {'_key': 'user_key'},\n",
    "        'Batch_cell_culture': {'_key': 'batch_key'},\n",
    "        'Run': [{'_key': 'run_key1'}, {'_key': 'run_key2'}, ...]\n",
    "        }\n",
    "        edges = {}\n",
    "        generate_project_edges(collections, edges)\n",
    "        # edges will be updated with edges between collections.\n",
    "    '''\n",
    "   \n",
    "    # edges.update({'has_batch': {'edges':[], \n",
    "    #                             'from_collection': ['Project'],\n",
    "    #                             'to_collection':['Batch_cell_culture']},\n",
    "    #             'created_by': {'edges':[],\n",
    "    #                             'from_collection': ['Project'],\n",
    "    #                             'to_collection':['User']},\n",
    "    #             'has_run': {'edges':[], \n",
    "    #                         'from_collection': ['Batch_cell_culture'],\n",
    "    #                         'to_collection':['Run']}\n",
    "    #                             })\n",
    "    \n",
    "    # for user in collections['User']:\n",
    "    #     for batch in collections['Batch_cell_culture']:\n",
    "    #         for project in collections['Project']:\n",
    "    #             if '_key' in project:\n",
    "    #                 edges['has_batch']['edges'].append({'_from': f\"Project/{project['_key']}\",\n",
    "    #                                                     '_to': f\"Batch_cell_culture/{batch['_key']}\"})\n",
    "    #                 edges['created_by']['edges'].append({'_from': f\"Project/{project['_key']}\",\n",
    "    #                                                     '_to': f\"User/{user['_key']}\"})\n",
    "    project = collections['Project']\n",
    "    user = collections['User']\n",
    "    batch = collections['Batch_cell_culture']\n",
    "\n",
    "    edges.update({'has_batch': {'edges':[{'_from': f\"Project/{project['_key']}\",\n",
    "                                          '_to': f\"Batch_cell_culture/{batch['_key']}\"}], \n",
    "                                'from_collection': ['Project'],\n",
    "                                'to_collection':['Batch_cell_culture']},\n",
    "                  'created_by': {'edges':[{'_from': f\"Project/{project['_key']}\",\n",
    "                                          '_to': f\"User/{user['_key']}\",\n",
    "                                          'creation_date': project['creation_time']}],\n",
    "                                'from_collection': ['Project'],\n",
    "                                'to_collection':['User']}})\n",
    "    edges.update({'has_run': {'edges':[], \n",
    "                              'from_collection': ['Batch_cell_culture'],\n",
    "                                'to_collection':['Run']}})\n",
    "    for run in collections['Run']:\n",
    "        edges['has_run']['edges'].append({'_from': f\"Batch_cell_culture/{batch['_key']}\",\n",
    "                                          '_to': f\"Run/{run['_key']}\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e59fda",
   "metadata": {},
   "source": [
    "### 4. Create iModulon node and edges collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ac1d797",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Define iModulon function \n",
    "def get_imodulon_collection(organism, dataset, table_path):\n",
    "    '''\n",
    "    Process iModulon data to generate a collection for a given organism and dataset. \n",
    "    - Reads data from a CSV file into a pandas DataFrame. \n",
    "    - Adds additional fields such as a key column from hashing name column, and creates linkout column by constructing URLs to generate individual links for each iModulon entry.\n",
    "    - Processes dataset by handling misisng values and dropping the 'k' column as it is no loger needed (values areincorporated into the linkout column) \n",
    "\n",
    "    parameters:\n",
    "        organism (str): The name of the organism (e.g., 'e_coli').\n",
    "        dataset (str): The name of the dataset (e.g., 'precise1k').\n",
    "        table_path (str): The file path to the CSV file containing the iModulon data (e.g., '/path/to/iM_table.csv').\n",
    "\n",
    "    return:\n",
    "        data_dict: A list of dictionaries representing processed iModulon data\n",
    "    '''\n",
    "    imodulon_link = f'https://imodulondb.org/iModulon.html?organism={organism}&dataset={dataset}&k='\n",
    "    data = pd.read_csv(table_path, sep=',', header=0)\n",
    "    data['_key'] = data['name'].apply(lambda n: get_hash(n, prefix=\"iM\"))\n",
    "    data['linkout'] = data['k'].apply(lambda k: imodulon_link+str(k))\n",
    "    data = data.fillna('NaN').drop('k', axis=1)\n",
    "    data_dict = data.to_dict(orient='records')\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2282c406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate iModulon collection\n",
    "collections['iModulon'] = []\n",
    "for organism in imodulon_files:\n",
    "    for dataset in imodulon_files[organism]:\n",
    "        imodulon_path = imodulon_files[organism][dataset]\n",
    "        collections['iModulon'].extend(get_imodulon_collection(organism=organism, dataset=dataset, table_path=imodulon_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3667915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create edges with conditions collections, phases collections and project edges\n",
    "\n",
    "edges = get_run_conditions(collections, rconfig)\n",
    "edges.update(get_run_phases(collections))\n",
    "generate_project_edges(collections, edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ab9977",
   "metadata": {},
   "source": [
    "### 5. Create species node and edge collections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47904fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/59/fbtwqg3d2r97w0gc059ff5qh0000gp/T/ipykernel_8522/3504519149.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  strain_mapping = {r[0]: {'name': r[1], 'taxid':r[2]} for i,r in strain_mapping.iterrows()}\n"
     ]
    }
   ],
   "source": [
    "with open(strain_mapping_path, 'r') as strain_file:\n",
    "    strain_mapping = pd.read_csv(strain_file, sep=',')\n",
    "\n",
    "# From df to dict\n",
    "strain_mapping = {r[0]: {'name': r[1], 'taxid':r[2]} for i,r in strain_mapping.iterrows()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0055c6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a Species collection: nodes and edges\n",
    "species = []\n",
    "\n",
    "# Create edge 'belongs_to'\n",
    "if 'belongs_to' not in edges:\n",
    "    edges['belongs_to'] = {\n",
    "        'edges': [],\n",
    "        'from_collection': ['Strain'],\n",
    "        'to_collection': ['Species']\n",
    "    }\n",
    "\n",
    "for strain in collections['Strain']:\n",
    "    strain_key = strain['_key']\n",
    "    name = strain['name']\n",
    "    if name in strain_mapping:\n",
    "        organism = strain_mapping[name]['name']\n",
    "        taxid = str(strain_mapping[name]['taxid'])\n",
    "        species.append({\n",
    "            '_key': taxid,\n",
    "            'name': organism,\n",
    "            'rank': 'species'\n",
    "        })\n",
    "        edges['belongs_to']['edges'].append({\n",
    "            '_from': f'Strain/{strain_key}',\n",
    "            '_to': f'Species/{taxid}'\n",
    "        })\n",
    "\n",
    "collections['Species'] = get_unique_json_from_list_of_dicts(d=species,\n",
    "                                                            unique_key='_key')                               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec2777b",
   "metadata": {},
   "source": [
    "### 6. Create institution node collection and edges collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39c25ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an Institution node collection with a document at its edges\n",
    "if 'Institution' not in collections:\n",
    "        institution_key = get_hash(\"NNFCB\", prefix=\"I\")\n",
    "        collections['Institution'] = [{'_key': institution_key,\n",
    "                                'name': 'NNFCB - Novo Nordisk Foundation Center for Biosustainability (DTU Biosustain)',\n",
    "                                'address': 'Building 220, Kemitorvet. 2800 Kgs. Lyngby',\n",
    "                                'email': 'biosustain@biosustain.dtu.dk',\n",
    "                                'phone_number':'+45 45 25 80 00'\n",
    "                                }]\n",
    "\n",
    "project = collections['Project']\n",
    "user = collections['User']\n",
    "country = collections['Country']\n",
    "\n",
    "edges.update({'created_at': {'edges':[{'_from': f\"Project/{project['_key']}\",\n",
    "                                          '_to': f\"Institution/{institution_key}\"}], \n",
    "                                'from_collection': ['Project'],\n",
    "                                'to_collection':['Institution']},\n",
    "                'works_at': {'edges':[{'_from': f\"User/{user['_key']}\",\n",
    "                                          '_to': f\"Institution/{institution_key}\"}],\n",
    "                                'from_collection': ['User'],\n",
    "                                'to_collection':['Institution']},\n",
    "                'from': {'edges':[{'_from': f\"Institution/{institution_key}\",\n",
    "                                          '_to': f\"Country/{country['_key']}\",\n",
    "                                          'creation_date': project['creation_time']}],\n",
    "                                'from_collection': ['Institution'],\n",
    "                                'to_collection':['Country']}})\n",
    "\n",
    "# ## Create 'created_at' edge\n",
    "# if 'created_at' not in edges:\n",
    "#         edges['created_at'] = {'edges': [],\n",
    "#                                 'from_collection': ['Project'],\n",
    "#                                 'to_collection': ['Institution']}\n",
    "\n",
    "# for project in collections['Project']:\n",
    "#         print(f\"Project: {project}\")\n",
    "#         project_key = int(project[\"_key\"])\n",
    "#         edges['created_at']['edges'].append({\n",
    "#                 '_from': f\"Project/{project_key}\",\n",
    "#                 '_to': f\"Institution/{institution_key}\"\n",
    "#         })\n",
    "\n",
    "# ## Create 'works_at' edge\n",
    "# if 'works_at' not in edges:\n",
    "#         edges['works_at'] = {'edges':[], \n",
    "#                                 'from_collection': ['User'],\n",
    "#                                 'to_collection': ['Institution']}\n",
    "\n",
    "# for user in collections['User']:\n",
    "#         user_key = int(user[\"_key\"])\n",
    "#         edges['works_at']['edges'].append({\n",
    "#                 '_from': f\"User/{user_key}\",\n",
    "#                 '_to': f\"Institution/{institution_key}\"\n",
    "#         })\n",
    "\n",
    "\n",
    "\n",
    "# ## Create 'from' edge\n",
    "# if 'from' not in edges:\n",
    "#         edges['from'] = {'edges': [],\n",
    "#                                 'from_collection': ['Institution'],\n",
    "#                                 'to_collection': ['Country']}\n",
    "\n",
    "# for country in collections['Country']:\n",
    "#         country_key = int(country[\"_key\"])\n",
    "#         edges['from']['edges'].append({\n",
    "#                 '_from': f\"Institution/{institution_key}\",\n",
    "#                 '_to': f\"Country/{country_key}\"\n",
    "#         })\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9ac80f",
   "metadata": {},
   "source": [
    "### 7. Output nodes and edges collections as two JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6c083fa-6595-47fa-98ce-8c9e6303ced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output nodes collections \n",
    "os.makedirs(os.path.dirname(nodes_path), exist_ok = True)\n",
    "nodes_str = json.dumps(collections)\n",
    "with open(nodes_path, 'w') as out:\n",
    "    out.write(nodes_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc77c8fc-1de8-4d62-aa43-6e2671b3d459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output edges collections\n",
    "os.makedirs(os.path.dirname(edges_path), exist_ok = True)\n",
    "edges_str = json.dumps(edges)\n",
    "with open(edges_path, 'w') as out:\n",
    "    out.write(edges_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
